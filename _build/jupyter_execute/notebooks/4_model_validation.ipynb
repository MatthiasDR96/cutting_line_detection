{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is a graphical card (CUDA) available on the PC\n",
    "device = torch.device(\"cuda:\" + str(torch.cuda.current_device()) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "batch_size = 16\n",
    "augmentation = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with image paths\n",
    "df_test = pd.read_pickle('../data/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name\n",
    "model_file_name = \"model_\" + str(learning_rate) + \"-\" + str(batch_size) + '-' + str(augmentation) + '-' + str(epochs)\n",
    "\n",
    "# Load model\n",
    "model = torch.load(\"../models/\" + model_file_name + \".pt\").to(device)\n",
    "\n",
    "# Set model to evaluate mode     \n",
    "ret = model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function draws an extended line on an image based on a slope and an intercept\n",
    "def draw_extended_line(image, a, b, color=(255, 0, 0), thickness=1):\n",
    "\t\t\n",
    "\t# Get image shape\n",
    "\t_, cols,*_ = image.shape\n",
    "\n",
    "\t# Create line points\n",
    "\tstart_point = (0, int(a*0 + b))\n",
    "\tend_point = (int(cols), int(a*cols + b))\n",
    "\t\n",
    "\t# Draw the extended line in red\n",
    "\timage = cv2.line(image, start_point, end_point, color, thickness)\n",
    "\t\n",
    "\treturn image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m b1 \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m a1\u001b[38;5;241m*\u001b[39my[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Predict line \u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(\u001b[43mtransformed_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()) \u001b[38;5;66;03m# Unsqueeze to solve for missing batch dimension\u001b[39;00m\n\u001b[0;32m     41\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Scale prediction to account for resizing\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python39\\lib\\site-packages\\torch\\cuda\\__init__.py:216\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[0;32m    220\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert all images and labels\n",
    "total_rmse = 0\n",
    "for i, row in df_test.iterrows():\n",
    "\n",
    "\t# Define subplot\n",
    "\tplt.subplot(3, 4, i+1)\n",
    "\n",
    "\t# Get the image path name\n",
    "\timg_path = row[\"path_names\"]\n",
    "\n",
    "\t# Read image\n",
    "\timage = cv2.imread(img_path) \n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\theight, width, channels = image.shape\n",
    "\n",
    "\t# Get label\n",
    "\tkey = img_path.split('\\\\')[-1].split('.')[0]\n",
    "\tlabel_file = open(\"../data/labels/\" + key + \".txt\", \"r\")\n",
    "\tlabeldata = label_file.read().split(\" \")\n",
    "\n",
    "\t# Get keypoints\n",
    "\ty = [(float(labeldata[4]), float(labeldata[5])), (float(labeldata[6]), float(labeldata[7]))]\n",
    "\n",
    "\t# Define augmentation pipeline\n",
    "\ttransform = A.Compose([\n",
    "\t\tA.Resize(224, 224),\n",
    "\t\tA.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "\t\tToTensorV2(),\n",
    "\t], keypoint_params=A.KeypointParams(format='xy', remove_invisible=True))\n",
    "\n",
    "\t# Transform\n",
    "\ttransformed = transform(image=image, keypoints=y)\n",
    "\ttransformed_image = transformed['image']\n",
    "\n",
    "\t# Get ground truth line\n",
    "\ta1 = 0 if (y[1][0] - y[0][0]) == 0 else (y[1][1] - y[0][1]) / (y[1][0] - y[0][0])\n",
    "\tb1 = y[0][1] - a1*y[0][0]\n",
    "\n",
    "\t# Predict line \n",
    "\tpred = model(transformed_image.unsqueeze(0).cuda().float()) # Unsqueeze to solve for missing batch dimension\n",
    "\tpred = pred.detach().cpu().numpy()[0]\n",
    "\n",
    "\t# Scale prediction to account for resizing\n",
    "\tpred[0] = pred[0] /224*width\n",
    "\tpred[1] = pred[1] /224*height\n",
    "\tpred[2] = pred[2] /224*width\n",
    "\tpred[3] = pred[3] /224*height\n",
    "\n",
    "\t# Get predicted line\n",
    "\ta2 = 0 if (pred[2] - pred[0]) == 0 else (pred[3] - pred[1]) / (pred[2] - pred[0])\n",
    "\tb2 = pred[1] - a2*pred[0]\n",
    "\n",
    "\t# Draw ground truth and predicted line\n",
    "\tdraw_extended_line(image, a1, b1, color=(0, 255, 0), thickness=3)\n",
    "\tdraw_extended_line(image, a2, b2, color=(255, 0, 0), thickness=3)\n",
    "\n",
    "\t# Visualize\n",
    "\tcv2.rectangle(image, (int(labeldata[0]), int(labeldata[1])), (int(labeldata[2]), int(labeldata[3])), (255, 0, 0), 1)\n",
    "\tplt.imshow(image)\n",
    "\n",
    "\t# Stop reading\n",
    "\tif i >= 3*4-1: break\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}